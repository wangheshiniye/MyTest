2019-04-26 11:50:25 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 11:50:25 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:22 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 11:51:29 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 11:51:29 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:8 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 14:04:23 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 14:04:23 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:16 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 14:36:28 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 14:36:28 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:0 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 14:36:32 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:3557 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 14:36:32 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:3599 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 14:36:32 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:3701 ] - [ INFO ]  number of splits:1 
2019-04-26 14:36:33 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:4190 ] - [ INFO ]  Submitting tokens for job: job_local1126784176_0001 
2019-04-26 14:36:33 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:4781 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 14:36:33 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:4782 ] - [ INFO ]  Running job: job_local1126784176_0001 
2019-04-26 14:36:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:4799 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 14:36:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:4834 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 14:36:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:4954 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 14:36:33 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:5034 ] - [ INFO ]  Starting task: attempt_local1126784176_0001_m_000000_0 
2019-04-26 14:36:34 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:5145 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 14:36:34 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:5468 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6e7f2886 
2019-04-26 14:36:34 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:5475 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 14:36:34 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:5614 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 14:36:34 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:5620 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 14:36:34 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:5620 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 14:36:34 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:5620 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 14:36:34 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:5621 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 14:36:34 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:5662 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 14:36:34 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:5790 ] - [ INFO ]  Job job_local1126784176_0001 running in uber mode : false 
2019-04-26 14:36:34 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:5797 ] - [ INFO ]   map 0% reduce 0% 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:6233 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:6323 ] - [ INFO ]   
2019-04-26 14:36:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:6324 ] - [ INFO ]  Starting flush of map output 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:6400 ] - [ INFO ]  Task:attempt_local1126784176_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:6463 ] - [ INFO ]  map 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:6463 ] - [ INFO ]  Task 'attempt_local1126784176_0001_m_000000_0' done. 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:6463 ] - [ INFO ]  Finishing task: attempt_local1126784176_0001_m_000000_0 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:6463 ] - [ INFO ]  map task executor complete. 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:6494 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:6494 ] - [ INFO ]  Starting task: attempt_local1126784176_0001_r_000000_0 
2019-04-26 14:36:35 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:6554 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:6676 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7840e96c 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:6676 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7f15654d 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:6707 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:6723 ] - [ INFO ]  attempt_local1126784176_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:6802 ] - [ INFO ]   map 100% reduce 0% 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:6822 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1126784176_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:6864 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local1126784176_0001_m_000000_0 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:6959 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:6959 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:6975 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:6975 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:7022 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:7023 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:7027 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:7030 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 14:36:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:7031 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:7032 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:7045 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:7046 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 14:36:35 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:7050 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:7058 ] - [ INFO ]  Task:attempt_local1126784176_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:7058 ] - [ INFO ]  reduce > reduce 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:7058 ] - [ INFO ]  Task 'attempt_local1126784176_0001_r_000000_0' done. 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:7058 ] - [ INFO ]  Finishing task: attempt_local1126784176_0001_r_000000_0 
2019-04-26 14:36:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:7058 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 14:36:36 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:7805 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 14:36:36 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:7807 ] - [ INFO ]  Job job_local1126784176_0001 completed successfully 
2019-04-26 14:36:36 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:7883 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=50160
		FILE: Number of bytes written=504588
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=16
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=578813952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 14:40:00 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 14:40:00 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:0 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 14:40:02 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:2637 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 14:40:03 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:2697 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 14:40:03 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:2894 ] - [ INFO ]  number of splits:1 
2019-04-26 14:40:03 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:3408 ] - [ INFO ]  Submitting tokens for job: job_local158469282_0001 
2019-04-26 14:40:04 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:3978 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 14:40:04 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:3979 ] - [ INFO ]  Running job: job_local158469282_0001 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:4052 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:4066 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:4227 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:4259 ] - [ INFO ]  Starting task: attempt_local158469282_0001_m_000000_0 
2019-04-26 14:40:04 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:4319 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:4490 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1147d0ad 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:4496 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:4600 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:4603 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:4603 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:4603 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:4604 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 14:40:04 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:4611 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:4742 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:4805 ] - [ INFO ]   
2019-04-26 14:40:05 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:4805 ] - [ INFO ]  Starting flush of map output 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:4867 ] - [ INFO ]  Task:attempt_local158469282_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:4883 ] - [ INFO ]  map 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:4883 ] - [ INFO ]  Task 'attempt_local158469282_0001_m_000000_0' done. 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:4883 ] - [ INFO ]  Finishing task: attempt_local158469282_0001_m_000000_0 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:4883 ] - [ INFO ]  map task executor complete. 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:4883 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:4898 ] - [ INFO ]  Starting task: attempt_local158469282_0001_r_000000_0 
2019-04-26 14:40:05 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:4898 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:4995 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@738dd1b3 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:4995 ] - [ INFO ]  Job job_local158469282_0001 running in uber mode : false 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:4995 ] - [ INFO ]   map 100% reduce 0% 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:4995 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22be9f8f 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:5041 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:5057 ] - [ INFO ]  attempt_local158469282_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:5135 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local158469282_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:5146 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local158469282_0001_m_000000_0 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:5186 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:5186 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:5186 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:5186 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:5202 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:5202 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:5202 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:5202 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 14:40:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:5202 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:5202 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:5217 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:5217 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 14:40:05 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:5217 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:5217 ] - [ INFO ]  Task:attempt_local158469282_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:5233 ] - [ INFO ]  reduce > reduce 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:5233 ] - [ INFO ]  Task 'attempt_local158469282_0001_r_000000_0' done. 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:5233 ] - [ INFO ]  Finishing task: attempt_local158469282_0001_r_000000_0 
2019-04-26 14:40:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:5233 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 14:40:06 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:5996 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 14:40:06 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:5999 ] - [ INFO ]  Job job_local158469282_0001 completed successfully 
2019-04-26 14:40:06 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:6023 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=38930
		FILE: Number of bytes written=501844
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=18
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=508559360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 14:44:26 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 14:44:27 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ main:928 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 14:45:03 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 14:45:04 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ main:909 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 14:45:32 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 14:45:32 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:0 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 14:45:35 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:3589 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 14:45:35 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:3605 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 14:45:35 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:3828 ] - [ INFO ]  number of splits:1 
2019-04-26 14:45:36 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:4265 ] - [ INFO ]  Submitting tokens for job: job_local570499650_0001 
2019-04-26 14:45:36 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:4783 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 14:45:36 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:4783 ] - [ INFO ]  Running job: job_local570499650_0001 
2019-04-26 14:45:36 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:4799 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 14:45:36 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:4799 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 14:45:36 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:4901 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 14:45:36 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:4902 ] - [ INFO ]  Starting task: attempt_local570499650_0001_m_000000_0 
2019-04-26 14:45:37 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:4954 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:5117 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1147d0ad 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:5117 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:5211 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:5211 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:5211 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:5211 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:5211 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:5226 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 14:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:5289 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:5420 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 14:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:5421 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:5455 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:5460 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:5462 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:5464 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:5481 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:5481 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:5481 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:5496 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:5496 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:5496 ] - [ INFO ]   
2019-04-26 14:45:37 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:5496 ] - [ INFO ]  Starting flush of map output 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:5528 ] - [ INFO ]  Task:attempt_local570499650_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:5543 ] - [ INFO ]  map 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:5543 ] - [ INFO ]  Task 'attempt_local570499650_0001_m_000000_0' done. 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:5543 ] - [ INFO ]  Finishing task: attempt_local570499650_0001_m_000000_0 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:5543 ] - [ INFO ]  map task executor complete. 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:5543 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:5543 ] - [ INFO ]  Starting task: attempt_local570499650_0001_r_000000_0 
2019-04-26 14:45:37 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:5559 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:5670 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@22dd77df 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:5675 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1ef6a962 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:5695 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:5695 ] - [ INFO ]  attempt_local570499650_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:5774 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local570499650_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:5780 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local570499650_0001_m_000000_0 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:5796 ] - [ INFO ]  Job job_local570499650_0001 running in uber mode : false 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:5796 ] - [ INFO ]   map 100% reduce 0% 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:5811 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:5811 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:5811 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:5811 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:5843 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:5843 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:5843 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:5843 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 14:45:37 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:5843 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:5843 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:5858 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:5858 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 14:45:37 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:5867 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:5875 ] - [ INFO ]  Task:attempt_local570499650_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:5878 ] - [ INFO ]  reduce > reduce 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:5879 ] - [ INFO ]  Task 'attempt_local570499650_0001_r_000000_0' done. 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:5879 ] - [ INFO ]  Finishing task: attempt_local570499650_0001_r_000000_0 
2019-04-26 14:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:5880 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 14:45:38 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:6805 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 14:45:38 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:6805 ] - [ INFO ]  Job job_local570499650_0001 completed successfully 
2019-04-26 14:45:38 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:6805 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=39364
		FILE: Number of bytes written=501844
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=18
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=511705088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 14:47:01 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 14:47:01 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:7 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 14:47:03 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:2287 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 14:47:03 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:2343 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 14:47:03 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:2450 ] - [ INFO ]  number of splits:1 
2019-04-26 14:47:03 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:2797 ] - [ INFO ]  Submitting tokens for job: job_local61610085_0001 
2019-04-26 14:47:04 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:3353 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 14:47:04 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:3354 ] - [ INFO ]  Running job: job_local61610085_0001 
2019-04-26 14:47:04 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:3370 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 14:47:04 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:3382 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 14:47:04 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:3475 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 14:47:04 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:3476 ] - [ INFO ]  Starting task: attempt_local61610085_0001_m_000000_0 
2019-04-26 14:47:04 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:3549 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 14:47:04 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:3753 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5a91f5a1 
2019-04-26 14:47:04 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:3760 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:3848 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:3862 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:3862 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:3862 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:3863 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:3868 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 14:47:05 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3898 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:4023 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 14:47:05 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4023 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:47:05 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4023 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:47:05 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4038 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:47:05 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4038 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:47:05 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4054 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:47:05 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4054 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:47:05 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4054 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:47:05 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4070 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:47:05 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4070 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:47:05 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4070 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:4085 ] - [ INFO ]   
2019-04-26 14:47:05 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:4085 ] - [ INFO ]  Starting flush of map output 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:4210 ] - [ INFO ]  Task:attempt_local61610085_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:4214 ] - [ INFO ]  map 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:4214 ] - [ INFO ]  Task 'attempt_local61610085_0001_m_000000_0' done. 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:4214 ] - [ INFO ]  Finishing task: attempt_local61610085_0001_m_000000_0 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:4214 ] - [ INFO ]  map task executor complete. 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:4230 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:4230 ] - [ INFO ]  Starting task: attempt_local61610085_0001_r_000000_0 
2019-04-26 14:47:05 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:4250 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:4366 ] - [ INFO ]  Job job_local61610085_0001 running in uber mode : false 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:4369 ] - [ INFO ]   map 100% reduce 0% 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:4489 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7193802f 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:4494 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ee9f7c1 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:4517 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:4525 ] - [ INFO ]  attempt_local61610085_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:4595 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local61610085_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:4606 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local61610085_0001_m_000000_0 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:4670 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:4670 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:4670 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:4670 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:4733 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:4734 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:4739 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:4746 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 14:47:05 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:4751 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:4751 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:4761 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:4763 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 14:47:05 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:4767 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:4783 ] - [ INFO ]  Task:attempt_local61610085_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:4786 ] - [ INFO ]  reduce > reduce 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:4786 ] - [ INFO ]  Task 'attempt_local61610085_0001_r_000000_0' done. 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:4787 ] - [ INFO ]  Finishing task: attempt_local61610085_0001_r_000000_0 
2019-04-26 14:47:05 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:4787 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 14:47:06 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:5380 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 14:47:06 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:5380 ] - [ INFO ]  Job job_local61610085_0001 completed successfully 
2019-04-26 14:47:06 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:5408 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=39364
		FILE: Number of bytes written=499108
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=578813952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 14:48:50 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 14:48:50 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:0 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 14:48:53 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:2778 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 14:48:53 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:2793 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 14:48:53 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:2876 ] - [ INFO ]  number of splits:1 
2019-04-26 14:48:53 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:3175 ] - [ INFO ]  Submitting tokens for job: job_local1354432039_0001 
2019-04-26 14:48:54 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:3633 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 14:48:54 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:3635 ] - [ INFO ]  Running job: job_local1354432039_0001 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:3642 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:3653 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:3785 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:3787 ] - [ INFO ]  Starting task: attempt_local1354432039_0001_m_000000_0 
2019-04-26 14:48:54 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:3873 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:4086 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1147d0ad 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:4093 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:4211 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:4219 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:4219 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:4220 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:4220 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 14:48:54 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:4227 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 14:48:54 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4275 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 14:48:54 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:4430 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 14:48:54 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4432 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:48:54 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4443 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:48:54 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4448 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:48:54 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4454 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:48:55 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4459 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:48:55 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4464 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:48:55 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4479 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:48:55 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4486 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:48:55 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4490 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:48:55 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:4498 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:4507 ] - [ INFO ]   
2019-04-26 14:48:55 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:4507 ] - [ INFO ]  Starting flush of map output 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:4572 ] - [ INFO ]  Task:attempt_local1354432039_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:4588 ] - [ INFO ]  map 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:4588 ] - [ INFO ]  Task 'attempt_local1354432039_0001_m_000000_0' done. 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:4588 ] - [ INFO ]  Finishing task: attempt_local1354432039_0001_m_000000_0 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:4588 ] - [ INFO ]  map task executor complete. 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:4588 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:4588 ] - [ INFO ]  Starting task: attempt_local1354432039_0001_r_000000_0 
2019-04-26 14:48:55 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:4619 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:4666 ] - [ INFO ]  Job job_local1354432039_0001 running in uber mode : false 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:4666 ] - [ INFO ]   map 100% reduce 0% 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:4807 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@526cfdef 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:4813 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@93f95d6 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:4835 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:4844 ] - [ INFO ]  attempt_local1354432039_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:4916 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1354432039_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:4927 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local1354432039_0001_m_000000_0 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:4971 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:4971 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:4971 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:4971 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:4986 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:4986 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:4986 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:4986 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 14:48:55 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:4986 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:4986 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:5002 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:5002 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 14:48:55 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:5002 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:5002 ] - [ INFO ]  Task:attempt_local1354432039_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:5002 ] - [ INFO ]  reduce > reduce 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:5002 ] - [ INFO ]  Task 'attempt_local1354432039_0001_r_000000_0' done. 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:5002 ] - [ INFO ]  Finishing task: attempt_local1354432039_0001_r_000000_0 
2019-04-26 14:48:55 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:5002 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 14:48:56 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:5687 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 14:48:56 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:5687 ] - [ INFO ]  Job job_local1354432039_0001 completed successfully 
2019-04-26 14:48:56 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:5703 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=39364
		FILE: Number of bytes written=504572
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=578813952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 14:49:49 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 14:49:50 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ main:771 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 15:01:54 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 15:01:55 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:809 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 15:06:41 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 15:06:42 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:781 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 15:15:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 15:15:52 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:2624 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 15:20:00 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 15:20:03 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:2722 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 15:22:36 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 15:22:39 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:2592 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 15:28:41 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 15:28:43 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:2425 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 15:34:00 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 15:34:03 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:2502 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 15:35:00 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 15:45:46 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 15:46:15 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:1 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 15:46:18 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:2690 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 15:47:05 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 15:47:08 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:18)] - [ main:2409 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:01:34 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 16:01:37 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ main:3156 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:03:48 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 16:03:50 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ main:2034 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:04:37 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 16:04:39 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ main:1982 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:06:06 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 16:06:08 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ main:1902 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:07:29 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:1 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 16:07:29 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:7 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 16:07:32 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:2395 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 16:07:32 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:2419 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 16:07:32 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:2490 ] - [ INFO ]  number of splits:1 
2019-04-26 16:07:32 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:2833 ] - [ INFO ]  Submitting tokens for job: job_local1399568483_0001 
2019-04-26 16:07:32 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:3224 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 16:07:32 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:3224 ] - [ INFO ]  Running job: job_local1399568483_0001 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:3271 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:3286 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:3380 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:3380 ] - [ INFO ]  Starting task: attempt_local1399568483_0001_m_000000_0 
2019-04-26 16:07:33 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:3433 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:3618 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4cc68af8 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:3625 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:3712 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:3714 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:3714 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:3714 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:3715 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:3719 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 16:07:33 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:3729 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 16:07:33 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:3804 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 16:07:33 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:3804 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:07:33 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:3820 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:07:33 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:3820 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:07:33 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:3820 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:07:33 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:3835 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:07:33 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:3835 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:07:33 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:3835 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:07:33 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:3851 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:07:33 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:3864 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:07:33 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:3869 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:3875 ] - [ INFO ]   
2019-04-26 16:07:33 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:3876 ] - [ INFO ]  Starting flush of map output 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:3933 ] - [ INFO ]  Task:attempt_local1399568483_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:3936 ] - [ INFO ]  map 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:3936 ] - [ INFO ]  Task 'attempt_local1399568483_0001_m_000000_0' done. 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:3936 ] - [ INFO ]  Finishing task: attempt_local1399568483_0001_m_000000_0 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:3936 ] - [ INFO ]  map task executor complete. 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:3952 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:3952 ] - [ INFO ]  Starting task: attempt_local1399568483_0001_r_000000_0 
2019-04-26 16:07:33 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:3952 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:4030 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@47ec1db0 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:4030 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c1768fe 
2019-04-26 16:07:33 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:4061 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 16:07:33 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:4061 ] - [ INFO ]  attempt_local1399568483_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 16:07:33 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:4108 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1399568483_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 16:07:33 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:4124 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local1399568483_0001_m_000000_0 
2019-04-26 16:07:33 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:4155 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 16:07:33 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:4155 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:4155 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 16:07:33 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:4155 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:4186 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:4186 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 16:07:33 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:4186 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 16:07:33 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:4186 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 16:07:33 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:4186 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:4186 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:4202 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:4202 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 16:07:33 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:4202 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:4217 ] - [ INFO ]  Task:attempt_local1399568483_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:4217 ] - [ INFO ]  reduce > reduce 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:4217 ] - [ INFO ]  Task 'attempt_local1399568483_0001_r_000000_0' done. 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:4217 ] - [ INFO ]  Finishing task: attempt_local1399568483_0001_r_000000_0 
2019-04-26 16:07:33 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:4217 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 16:07:34 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:4233 ] - [ INFO ]  Job job_local1399568483_0001 running in uber mode : false 
2019-04-26 16:07:34 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:4249 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 16:07:35 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:5264 ] - [ INFO ]  Job job_local1399568483_0001 completed successfully 
2019-04-26 16:07:35 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:5280 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=12754
		FILE: Number of bytes written=504572
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=508559360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 16:11:21 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ main:0 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 16:11:22 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ main:635 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 16:11:45 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:1 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 16:11:45 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:7 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 16:11:48 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:2718 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 16:11:48 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:2737 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 16:11:48 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:2819 ] - [ INFO ]  number of splits:1 
2019-04-26 16:11:48 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:3163 ] - [ INFO ]  Submitting tokens for job: job_local2109242905_0001 
2019-04-26 16:11:49 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:3754 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 16:11:49 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:3756 ] - [ INFO ]  Running job: job_local2109242905_0001 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:3762 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:3777 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:3885 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:3890 ] - [ INFO ]  Starting task: attempt_local2109242905_0001_m_000000_0 
2019-04-26 16:11:49 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:3967 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:4210 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@458e8b00 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:4216 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:4321 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:4328 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:4328 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:4328 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:4328 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:4336 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 16:11:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:4379 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 16:11:49 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:4513 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 16:11:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:4519 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:11:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:4528 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:11:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:4531 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:11:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:4534 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:11:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:4537 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:11:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:4542 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:11:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:4545 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:11:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:4548 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:11:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:4553 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:11:49 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:19)] - [ LocalJobRunner Map Task Executor #0:4556 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:4562 ] - [ INFO ]   
2019-04-26 16:11:49 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:4562 ] - [ INFO ]  Starting flush of map output 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:4596 ] - [ INFO ]  Task:attempt_local2109242905_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:4611 ] - [ INFO ]  map 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:4612 ] - [ INFO ]  Task 'attempt_local2109242905_0001_m_000000_0' done. 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:4612 ] - [ INFO ]  Finishing task: attempt_local2109242905_0001_m_000000_0 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:4613 ] - [ INFO ]  map task executor complete. 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:4622 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 16:11:49 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:4622 ] - [ INFO ]  Starting task: attempt_local2109242905_0001_r_000000_0 
2019-04-26 16:11:50 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:4633 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:4755 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@51586211 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:4762 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1be032b 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:4779 ] - [ INFO ]  Job job_local2109242905_0001 running in uber mode : false 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:4782 ] - [ INFO ]   map 100% reduce 0% 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:4787 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:4826 ] - [ INFO ]  attempt_local2109242905_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:4959 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local2109242905_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:4979 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local2109242905_0001_m_000000_0 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:5084 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:5087 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:5088 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:5088 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:5110 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:5110 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:5115 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:5119 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 16:11:50 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:5121 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:5121 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:5126 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:5127 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 16:11:50 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:5130 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:5137 ] - [ INFO ]  Task:attempt_local2109242905_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:5140 ] - [ INFO ]  reduce > reduce 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:5141 ] - [ INFO ]  Task 'attempt_local2109242905_0001_r_000000_0' done. 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:5141 ] - [ INFO ]  Finishing task: attempt_local2109242905_0001_r_000000_0 
2019-04-26 16:11:50 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:5141 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 16:11:51 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:5788 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 16:11:51 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:5788 ] - [ INFO ]  Job job_local2109242905_0001 completed successfully 
2019-04-26 16:11:51 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:5805 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=64940
		FILE: Number of bytes written=504572
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=22
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=511705088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 16:16:08 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 16:16:08 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:6 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 16:16:11 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:2389 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 16:16:11 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:2430 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 16:16:11 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:2553 ] - [ INFO ]  number of splits:1 
2019-04-26 16:16:11 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:2875 ] - [ INFO ]  Submitting tokens for job: job_local646997808_0001 
2019-04-26 16:16:12 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:3411 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 16:16:12 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:3413 ] - [ INFO ]  Running job: job_local646997808_0001 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:3415 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:3426 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:3556 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:3567 ] - [ INFO ]  Starting task: attempt_local646997808_0001_m_000000_0 
2019-04-26 16:16:12 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:3662 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:3912 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3f0b62b5 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:3919 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:4025 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:4028 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:4028 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:4028 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:4029 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:4034 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 16:16:12 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:4070 ] - [ INFO ]  =======Algorithm :: invoke :: className = rule======= 
2019-04-26 16:16:12 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:4169 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 16:16:12 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:4170 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:16:12 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:4177 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:16:12 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:4179 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:16:12 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:4184 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:16:12 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:4189 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:16:12 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:4192 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:16:12 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:4195 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:16:12 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:4200 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:16:12 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:4204 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:16:12 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:4208 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 16:16:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:4212 ] - [ INFO ]   
2019-04-26 16:16:12 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:4212 ] - [ INFO ]  Starting flush of map output 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:4258 ] - [ INFO ]  Task:attempt_local646997808_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:4270 ] - [ INFO ]  map 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:4270 ] - [ INFO ]  Task 'attempt_local646997808_0001_m_000000_0' done. 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:4270 ] - [ INFO ]  Finishing task: attempt_local646997808_0001_m_000000_0 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:4271 ] - [ INFO ]  map task executor complete. 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:4274 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:4274 ] - [ INFO ]  Starting task: attempt_local646997808_0001_r_000000_0 
2019-04-26 16:16:13 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:4284 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:4368 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1c58f805 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:4373 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@689c3288 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:4396 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:4399 ] - [ INFO ]  attempt_local646997808_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:4417 ] - [ INFO ]  Job job_local646997808_0001 running in uber mode : false 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:4441 ] - [ INFO ]   map 100% reduce 0% 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:4472 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local646997808_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:4480 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local646997808_0001_m_000000_0 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:4517 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:4518 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:4519 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:4520 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:4535 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:4535 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:4539 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:4543 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 16:16:13 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:4545 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:4545 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:4549 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:4550 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 16:16:13 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:4552 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:4557 ] - [ INFO ]  Task:attempt_local646997808_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:4559 ] - [ INFO ]  reduce > reduce 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:4559 ] - [ INFO ]  Task 'attempt_local646997808_0001_r_000000_0' done. 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:4560 ] - [ INFO ]  Finishing task: attempt_local646997808_0001_r_000000_0 
2019-04-26 16:16:13 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:4560 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 16:16:14 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:5442 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 16:16:14 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:5442 ] - [ INFO ]  Job job_local646997808_0001 completed successfully 
2019-04-26 16:16:14 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:5459 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=62866
		FILE: Number of bytes written=501844
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=511705088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 17:18:21 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 17:18:21 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:16 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 17:18:22 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:1588 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 17:18:22 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:1592 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 17:18:22 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:1654 ] - [ INFO ]  number of splits:1 
2019-04-26 17:18:23 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:1998 ] - [ INFO ]  Submitting tokens for job: job_local1434497930_0001 
2019-04-26 17:18:23 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:2355 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 17:18:23 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:2355 ] - [ INFO ]  Running job: job_local1434497930_0001 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:2355 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:2371 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:2464 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:2464 ] - [ INFO ]  Starting task: attempt_local1434497930_0001_m_000000_0 
2019-04-26 17:18:23 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:2556 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:2672 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@458e8b00 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:2672 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:2765 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:2765 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:2765 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:2765 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:2765 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 17:18:23 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:2765 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 17:18:23 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2797 ] - [ INFO ]  =======Algorithm :: invoke :: className = log======= 
2019-04-26 17:18:23 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:2797 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 17:18:23 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2797 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:18:23 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2797 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:18:23 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2797 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:18:23 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2812 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:18:23 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2812 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:18:23 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2812 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:18:24 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2828 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:18:24 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2828 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:18:24 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2828 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:18:24 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2843 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:2843 ] - [ INFO ]   
2019-04-26 17:18:24 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:2843 ] - [ INFO ]  Starting flush of map output 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:2875 ] - [ INFO ]  Task:attempt_local1434497930_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:2875 ] - [ INFO ]  map 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:2875 ] - [ INFO ]  Task 'attempt_local1434497930_0001_m_000000_0' done. 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:2875 ] - [ INFO ]  Finishing task: attempt_local1434497930_0001_m_000000_0 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:2875 ] - [ INFO ]  map task executor complete. 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:2890 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:2890 ] - [ INFO ]  Starting task: attempt_local1434497930_0001_r_000000_0 
2019-04-26 17:18:24 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:2906 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:3047 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6deab449 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:3062 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4cdd7469 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:3093 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:3093 ] - [ INFO ]  attempt_local1434497930_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:3236 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1434497930_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:3245 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local1434497930_0001_m_000000_0 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:3322 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:3324 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3326 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:3326 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:3356 ] - [ INFO ]  Job job_local1434497930_0001 running in uber mode : false 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:3357 ] - [ INFO ]   map 100% reduce 0% 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3365 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3365 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:3368 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:3370 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 17:18:24 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:3371 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3371 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3375 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3376 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 17:18:24 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:3378 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:3384 ] - [ INFO ]  Task:attempt_local1434497930_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3385 ] - [ INFO ]  reduce > reduce 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:3386 ] - [ INFO ]  Task 'attempt_local1434497930_0001_r_000000_0' done. 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:3386 ] - [ INFO ]  Finishing task: attempt_local1434497930_0001_r_000000_0 
2019-04-26 17:18:24 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:3386 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 17:18:25 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:4369 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 17:18:25 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:4369 ] - [ INFO ]  Job job_local1434497930_0001 completed successfully 
2019-04-26 17:18:25 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:4384 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=24360
		FILE: Number of bytes written=504572
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=511705088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 17:19:59 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 17:19:59 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:16 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 17:20:00 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:1609 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 17:20:00 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:1627 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 17:20:00 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:1707 ] - [ INFO ]  number of splits:1 
2019-04-26 17:20:01 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:2129 ] - [ INFO ]  Submitting tokens for job: job_local344131554_0001 
2019-04-26 17:20:01 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:2474 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 17:20:01 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:2474 ] - [ INFO ]  Running job: job_local344131554_0001 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:2474 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:2489 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:2555 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:2555 ] - [ INFO ]  Starting task: attempt_local344131554_0001_m_000000_0 
2019-04-26 17:20:01 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:2596 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:2698 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@24954b7b 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:2698 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:2777 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:2777 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:2777 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:2777 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:2792 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 17:20:01 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:2792 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 17:20:01 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2808 ] - [ INFO ]  =======Algorithm :: invoke :: className = log======= 
2019-04-26 17:20:01 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:2889 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 17:20:01 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2889 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:20:01 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2889 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:20:01 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2889 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:20:01 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2905 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:20:01 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2905 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:20:01 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2905 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:20:01 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2905 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:20:02 [org.apache.hadoop.io.compress.zlib.ZlibFactory.<clinit>(ZlibFactory.java:51)] - [ LocalJobRunner Map Task Executor #0:2967 ] - [ WARN ]  Failed to load/initialize native-zlib library 
2019-04-26 17:20:02 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2967 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:20:02 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2967 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:20:02 [com.tjdata.mr.core.Algorithm.invoke(Algorithm.java:17)] - [ LocalJobRunner Map Task Executor #0:2967 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:2967 ] - [ INFO ]   
2019-04-26 17:20:02 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:2967 ] - [ INFO ]  Starting flush of map output 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:2999 ] - [ INFO ]  Task:attempt_local344131554_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:3030 ] - [ INFO ]   
2019-04-26 17:20:02 [org.apache.hadoop.mapred.Task.commit(Task.java:1162)] - [ LocalJobRunner Map Task Executor #0:3030 ] - [ INFO ]  Task attempt_local344131554_0001_m_000000_0 is allowed to commit now 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] - [ LocalJobRunner Map Task Executor #0:3030 ] - [ INFO ]  Saved output of task 'attempt_local344131554_0001_m_000000_0' to file:/E:/test/mobile_log/_temp/_temporary/0/task_local344131554_0001_m_000000 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:3030 ] - [ INFO ]  map 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:3030 ] - [ INFO ]  Task 'attempt_local344131554_0001_m_000000_0' done. 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:3030 ] - [ INFO ]  Finishing task: attempt_local344131554_0001_m_000000_0 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:3030 ] - [ INFO ]  map task executor complete. 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:3030 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:3030 ] - [ INFO ]  Starting task: attempt_local344131554_0001_r_000000_0 
2019-04-26 17:20:02 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:3046 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:3155 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@28e5f291 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:3155 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@464286a3 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:3202 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:3217 ] - [ INFO ]  attempt_local344131554_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:3406 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local344131554_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:3417 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local344131554_0001_m_000000_0 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:3469 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:3470 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3472 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:3472 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:3476 ] - [ INFO ]  Job job_local344131554_0001 running in uber mode : false 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:3511 ] - [ INFO ]   map 100% reduce 0% 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3523 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3524 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:3527 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:3529 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 17:20:02 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:3531 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3531 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3536 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3537 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 17:20:02 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:3540 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:3546 ] - [ INFO ]  Task:attempt_local344131554_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3546 ] - [ INFO ]  reduce > reduce 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:3546 ] - [ INFO ]  Task 'attempt_local344131554_0001_r_000000_0' done. 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:3546 ] - [ INFO ]  Finishing task: attempt_local344131554_0001_r_000000_0 
2019-04-26 17:20:02 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:3546 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 17:20:03 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:4518 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 17:20:03 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:4518 ] - [ INFO ]  Job job_local344131554_0001 completed successfully 
2019-04-26 17:20:03 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:4534 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=60126
		FILE: Number of bytes written=502884
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=19
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=511705088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 17:27:08 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 17:27:08 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:15 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 17:27:10 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:1987 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 17:27:10 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:2018 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 17:27:10 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:2112 ] - [ INFO ]  number of splits:1 
2019-04-26 17:27:11 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:2409 ] - [ INFO ]  Submitting tokens for job: job_local1548350332_0001 
2019-04-26 17:27:11 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:2800 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 17:27:11 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:2800 ] - [ INFO ]  Running job: job_local1548350332_0001 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:2800 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:2821 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:2882 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:2882 ] - [ INFO ]  Starting task: attempt_local1548350332_0001_m_000000_0 
2019-04-26 17:27:11 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:2929 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:3049 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4cc68af8 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:3055 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:3130 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:3130 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:3130 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:3130 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:3130 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 17:27:11 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:3130 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 17:27:11 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3161 ] - [ INFO ]  =======Algorithm :: invoke :: className = rl======= 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:3266 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 17:27:12 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3282 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:27:12 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3282 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:27:12 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3282 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:27:12 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3282 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:27:12 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3282 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:27:12 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3282 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:27:12 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3298 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:27:12 [org.apache.hadoop.io.compress.zlib.ZlibFactory.<clinit>(ZlibFactory.java:51)] - [ LocalJobRunner Map Task Executor #0:3313 ] - [ WARN ]  Failed to load/initialize native-zlib library 
2019-04-26 17:27:12 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3313 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:27:12 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3313 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:27:12 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3313 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:3329 ] - [ INFO ]   
2019-04-26 17:27:12 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:3329 ] - [ INFO ]  Starting flush of map output 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:3360 ] - [ INFO ]  Task:attempt_local1548350332_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:3376 ] - [ INFO ]   
2019-04-26 17:27:12 [org.apache.hadoop.mapred.Task.commit(Task.java:1162)] - [ LocalJobRunner Map Task Executor #0:3376 ] - [ INFO ]  Task attempt_local1548350332_0001_m_000000_0 is allowed to commit now 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] - [ LocalJobRunner Map Task Executor #0:3376 ] - [ INFO ]  Saved output of task 'attempt_local1548350332_0001_m_000000_0' to file:/E:/test/mobile_log/_temp/_temporary/0/task_local1548350332_0001_m_000000 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:3376 ] - [ INFO ]  map 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:3391 ] - [ INFO ]  Task 'attempt_local1548350332_0001_m_000000_0' done. 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:3391 ] - [ INFO ]  Finishing task: attempt_local1548350332_0001_m_000000_0 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:3391 ] - [ INFO ]  map task executor complete. 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:3391 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:3407 ] - [ INFO ]  Starting task: attempt_local1548350332_0001_r_000000_0 
2019-04-26 17:27:12 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:3423 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:3530 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@78634aff 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:3538 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@60ac9587 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:3568 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:3581 ] - [ INFO ]  attempt_local1548350332_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:3645 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1548350332_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:3645 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local1548350332_0001_m_000000_0 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:3792 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:3793 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3795 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:3795 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3797 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3797 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:3813 ] - [ INFO ]  Job job_local1548350332_0001 running in uber mode : false 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:3813 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:3813 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:3813 ] - [ INFO ]   map 100% reduce 0% 
2019-04-26 17:27:12 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:3813 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3813 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3813 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3813 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 17:27:12 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:3813 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:3831 ] - [ INFO ]  Task:attempt_local1548350332_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3834 ] - [ INFO ]  reduce > reduce 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:3835 ] - [ INFO ]  Task 'attempt_local1548350332_0001_r_000000_0' done. 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:3835 ] - [ INFO ]  Finishing task: attempt_local1548350332_0001_r_000000_0 
2019-04-26 17:27:12 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:3835 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 17:27:13 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:4817 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 17:27:13 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:4818 ] - [ INFO ]  Job job_local1548350332_0001 completed successfully 
2019-04-26 17:27:13 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:4837 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=38354
		FILE: Number of bytes written=505612
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=508035072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 17:45:35 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 17:45:35 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:6 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 17:45:36 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:1461 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 17:45:36 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:1480 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 17:45:37 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:1527 ] - [ INFO ]  number of splits:1 
2019-04-26 17:45:37 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:1730 ] - [ INFO ]  Submitting tokens for job: job_local886139835_0001 
2019-04-26 17:45:37 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:2069 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 17:45:37 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:2071 ] - [ INFO ]  Running job: job_local886139835_0001 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:2072 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:2084 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:2165 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:2166 ] - [ INFO ]  Starting task: attempt_local886139835_0001_m_000000_0 
2019-04-26 17:45:37 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:2214 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:2323 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1d516b8 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:2323 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:2405 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:2421 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:2421 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:2421 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:2421 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 17:45:37 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:2421 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 17:45:37 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2454 ] - [ INFO ]  =======Algorithm :: invoke :: className = rl======= 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:2540 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 17:45:38 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2540 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:45:38 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2540 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:45:38 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2540 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:45:38 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2555 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:45:38 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2555 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:45:38 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2555 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:45:38 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2555 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:45:38 [org.apache.hadoop.io.compress.zlib.ZlibFactory.<clinit>(ZlibFactory.java:51)] - [ LocalJobRunner Map Task Executor #0:2608 ] - [ WARN ]  Failed to load/initialize native-zlib library 
2019-04-26 17:45:38 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2612 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:45:38 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2614 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:45:38 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2615 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:2615 ] - [ INFO ]   
2019-04-26 17:45:38 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:2615 ] - [ INFO ]  Starting flush of map output 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:2647 ] - [ INFO ]  Task:attempt_local886139835_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:2662 ] - [ INFO ]   
2019-04-26 17:45:38 [org.apache.hadoop.mapred.Task.commit(Task.java:1162)] - [ LocalJobRunner Map Task Executor #0:2662 ] - [ INFO ]  Task attempt_local886139835_0001_m_000000_0 is allowed to commit now 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] - [ LocalJobRunner Map Task Executor #0:2678 ] - [ INFO ]  Saved output of task 'attempt_local886139835_0001_m_000000_0' to file:/E:/test/mobile_log/_temp/_temporary/0/task_local886139835_0001_m_000000 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:2678 ] - [ INFO ]  map 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:2678 ] - [ INFO ]  Task 'attempt_local886139835_0001_m_000000_0' done. 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:2678 ] - [ INFO ]  Finishing task: attempt_local886139835_0001_m_000000_0 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:2678 ] - [ INFO ]  map task executor complete. 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:2678 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:2678 ] - [ INFO ]  Starting task: attempt_local886139835_0001_r_000000_0 
2019-04-26 17:45:38 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:2693 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:2787 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@15031ecd 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:2787 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@689c3288 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:2818 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:2818 ] - [ INFO ]  attempt_local886139835_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:2920 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local886139835_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:2932 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local886139835_0001_m_000000_0 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:2975 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:2975 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:2975 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:2975 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3006 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3006 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:3010 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:3012 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:3013 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3015 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3029 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3030 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 17:45:38 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:3033 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:3047 ] - [ INFO ]  Task:attempt_local886139835_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3051 ] - [ INFO ]  reduce > reduce 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:3051 ] - [ INFO ]  Task 'attempt_local886139835_0001_r_000000_0' done. 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:3051 ] - [ INFO ]  Finishing task: attempt_local886139835_0001_r_000000_0 
2019-04-26 17:45:38 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:3054 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:3073 ] - [ INFO ]  Job job_local886139835_0001 running in uber mode : false 
2019-04-26 17:45:38 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:3075 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 17:45:39 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:4080 ] - [ INFO ]  Job job_local886139835_0001 completed successfully 
2019-04-26 17:45:39 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:4080 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=38354
		FILE: Number of bytes written=502884
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=511705088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 17:47:28 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 17:47:28 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:4 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 17:47:30 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:2235 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 17:47:30 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:2251 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 17:47:30 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:2301 ] - [ INFO ]  number of splits:1 
2019-04-26 17:47:31 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:2566 ] - [ INFO ]  Submitting tokens for job: job_local1416432733_0001 
2019-04-26 17:47:31 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:2832 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 17:47:31 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:2832 ] - [ INFO ]  Running job: job_local1416432733_0001 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:2847 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:2870 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:2938 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:2939 ] - [ INFO ]  Starting task: attempt_local1416432733_0001_m_000000_0 
2019-04-26 17:47:31 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:2970 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:3063 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7bd760a1 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:3079 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:3158 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:3158 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:3158 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:3158 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:3158 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:3174 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 17:47:31 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3205 ] - [ INFO ]  =======Algorithm :: invoke :: className = rl======= 
2019-04-26 17:47:31 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:3275 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 17:47:31 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3275 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:47:31 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3275 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:47:31 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3275 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:47:31 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3275 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:47:31 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3275 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:47:31 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3290 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:47:31 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3290 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:47:31 [org.apache.hadoop.io.compress.zlib.ZlibFactory.<clinit>(ZlibFactory.java:51)] - [ LocalJobRunner Map Task Executor #0:3306 ] - [ WARN ]  Failed to load/initialize native-zlib library 
2019-04-26 17:47:31 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3324 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:47:31 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3327 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:47:31 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:3328 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:3335 ] - [ INFO ]   
2019-04-26 17:47:31 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:3336 ] - [ INFO ]  Starting flush of map output 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:3401 ] - [ INFO ]  Task:attempt_local1416432733_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:3422 ] - [ INFO ]   
2019-04-26 17:47:31 [org.apache.hadoop.mapred.Task.commit(Task.java:1162)] - [ LocalJobRunner Map Task Executor #0:3423 ] - [ INFO ]  Task attempt_local1416432733_0001_m_000000_0 is allowed to commit now 
2019-04-26 17:47:31 [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] - [ LocalJobRunner Map Task Executor #0:3427 ] - [ INFO ]  Saved output of task 'attempt_local1416432733_0001_m_000000_0' to file:/E:/test/mobile_log/_temp/_temporary/0/task_local1416432733_0001_m_000000 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:3427 ] - [ INFO ]  map 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:3427 ] - [ INFO ]  Task 'attempt_local1416432733_0001_m_000000_0' done. 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:3427 ] - [ INFO ]  Finishing task: attempt_local1416432733_0001_m_000000_0 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:3427 ] - [ INFO ]  map task executor complete. 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:3427 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 17:47:31 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:3427 ] - [ INFO ]  Starting task: attempt_local1416432733_0001_r_000000_0 
2019-04-26 17:47:31 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:3443 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:3521 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6895e114 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:3521 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@76f8b22 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:3552 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:3552 ] - [ INFO ]  attempt_local1416432733_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:3630 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1416432733_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:3630 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local1416432733_0001_m_000000_0 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:3677 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:3677 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3677 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:3677 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3693 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3693 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:3693 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:3693 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:3693 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3693 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3693 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3693 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 17:47:32 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:3708 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:3708 ] - [ INFO ]  Task:attempt_local1416432733_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3708 ] - [ INFO ]  reduce > reduce 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:3708 ] - [ INFO ]  Task 'attempt_local1416432733_0001_r_000000_0' done. 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:3708 ] - [ INFO ]  Finishing task: attempt_local1416432733_0001_r_000000_0 
2019-04-26 17:47:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:3708 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:3862 ] - [ INFO ]  Job job_local1416432733_0001 running in uber mode : false 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:3864 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:3865 ] - [ INFO ]  Job job_local1416432733_0001 completed successfully 
2019-04-26 17:47:32 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:3881 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=38354
		FILE: Number of bytes written=505612
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=578813952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 18:27:49 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 18:27:49 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:0 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 18:27:50 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:1584 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 18:27:50 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:1602 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 18:27:50 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:1646 ] - [ INFO ]  number of splits:1 
2019-04-26 18:27:51 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:1953 ] - [ INFO ]  Submitting tokens for job: job_local951272737_0001 
2019-04-26 18:27:51 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:2343 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 18:27:51 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:2345 ] - [ INFO ]  Running job: job_local951272737_0001 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:2347 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:2359 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:2414 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:2414 ] - [ INFO ]  Starting task: attempt_local951272737_0001_m_000000_0 
2019-04-26 18:27:51 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:2461 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:2589 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7f275219 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:2596 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:2701 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:2701 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:2701 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:2701 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:2701 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 18:27:51 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:2716 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 18:27:51 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2747 ] - [ INFO ]  =======Algorithm :: invoke :: className = rl======= 
2019-04-26 18:27:51 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:2841 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 18:27:51 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2841 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 18:27:51 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2841 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 18:27:51 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2841 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 18:27:51 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2861 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 18:27:51 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2863 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 18:27:51 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2865 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 18:27:51 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2866 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 18:27:52 [org.apache.hadoop.io.compress.zlib.ZlibFactory.<clinit>(ZlibFactory.java:51)] - [ LocalJobRunner Map Task Executor #0:2897 ] - [ WARN ]  Failed to load/initialize native-zlib library 
2019-04-26 18:27:52 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2897 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 18:27:52 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2897 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 18:27:52 [com.tjdata.mr.core.Algorithm.invoke(?:?)] - [ LocalJobRunner Map Task Executor #0:2897 ] - [ INFO ]  =======Algorithm :: invoke :: className = log4g======= 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:2913 ] - [ INFO ]   
2019-04-26 18:27:52 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:2913 ] - [ INFO ]  Starting flush of map output 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:2944 ] - [ INFO ]  Task:attempt_local951272737_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:2944 ] - [ INFO ]   
2019-04-26 18:27:52 [org.apache.hadoop.mapred.Task.commit(Task.java:1162)] - [ LocalJobRunner Map Task Executor #0:2944 ] - [ INFO ]  Task attempt_local951272737_0001_m_000000_0 is allowed to commit now 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] - [ LocalJobRunner Map Task Executor #0:2959 ] - [ INFO ]  Saved output of task 'attempt_local951272737_0001_m_000000_0' to file:/E:/test/mobile_log/_temp/20180620_833_02/_temporary/0/task_local951272737_0001_m_000000 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:2959 ] - [ INFO ]  map 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:2959 ] - [ INFO ]  Task 'attempt_local951272737_0001_m_000000_0' done. 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:2959 ] - [ INFO ]  Finishing task: attempt_local951272737_0001_m_000000_0 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:2959 ] - [ INFO ]  map task executor complete. 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:2959 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:2959 ] - [ INFO ]  Starting task: attempt_local951272737_0001_r_000000_0 
2019-04-26 18:27:52 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:2975 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:3053 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@59ce1eed 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:3069 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@334e9cde 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:3084 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:3084 ] - [ INFO ]  attempt_local951272737_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:3167 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local951272737_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:3183 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local951272737_0001_m_000000_0 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:3240 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:3242 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3243 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:3243 ] - [ INFO ]  finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3261 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3261 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:3265 ] - [ INFO ]  Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:3267 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:3269 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:3269 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:3274 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3275 ] - [ INFO ]  1 / 1 copied. 
2019-04-26 18:27:52 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:3278 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:3287 ] - [ INFO ]  Task:attempt_local951272737_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:3290 ] - [ INFO ]  reduce > reduce 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:3291 ] - [ INFO ]  Task 'attempt_local951272737_0001_r_000000_0' done. 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:3291 ] - [ INFO ]  Finishing task: attempt_local951272737_0001_r_000000_0 
2019-04-26 18:27:52 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:3292 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:3349 ] - [ INFO ]  Job job_local951272737_0001 running in uber mode : false 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:3349 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:3349 ] - [ INFO ]  Job job_local951272737_0001 completed successfully 
2019-04-26 18:27:52 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:3380 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=38354
		FILE: Number of bytes written=502948
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=371
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=16
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=511705088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 23:19:31 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 23:19:31 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:31 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 23:19:31 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:422 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 23:19:31 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:437 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 23:19:31 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:453 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 23:19:31 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:484 ] - [ INFO ]  number of splits:2 
2019-04-26 23:19:31 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:734 ] - [ INFO ]  Submitting tokens for job: job_local546651347_0001 
2019-04-26 23:19:31 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:937 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 23:19:31 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:937 ] - [ INFO ]  Running job: job_local546651347_0001 
2019-04-26 23:19:31 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:953 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 23:19:31 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:968 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:1047 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:1047 ] - [ INFO ]  Starting task: attempt_local546651347_0001_m_000000_0 
2019-04-26 23:19:32 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:1078 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:1156 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@34322abb 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:1172 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:1234 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:1234 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:1234 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:1234 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:1234 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:1250 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 23:19:32 [org.apache.hadoop.io.compress.zlib.ZlibFactory.<clinit>(ZlibFactory.java:51)] - [ LocalJobRunner Map Task Executor #0:1437 ] - [ WARN ]  Failed to load/initialize native-zlib library 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1453 ] - [ INFO ]   
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:1453 ] - [ INFO ]  Starting flush of map output 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:1468 ] - [ INFO ]  Task:attempt_local546651347_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1484 ] - [ INFO ]   
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Task.commit(Task.java:1162)] - [ LocalJobRunner Map Task Executor #0:1484 ] - [ INFO ]  Task attempt_local546651347_0001_m_000000_0 is allowed to commit now 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] - [ LocalJobRunner Map Task Executor #0:1484 ] - [ INFO ]  Saved output of task 'attempt_local546651347_0001_m_000000_0' to file:/E:/test/mobile_log/833/02/_temporary/0/task_local546651347_0001_m_000000 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1484 ] - [ INFO ]  map 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:1484 ] - [ INFO ]  Task 'attempt_local546651347_0001_m_000000_0' done. 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:1484 ] - [ INFO ]  Finishing task: attempt_local546651347_0001_m_000000_0 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:1484 ] - [ INFO ]  Starting task: attempt_local546651347_0001_m_000001_0 
2019-04-26 23:19:32 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:1500 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:1546 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2e451b94 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:1562 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=3g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+837 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:1609 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:1609 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:1609 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:1609 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:1609 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:1625 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:1687 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1687 ] - [ INFO ]   
2019-04-26 23:19:32 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:1687 ] - [ INFO ]  Starting flush of map output 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:1718 ] - [ INFO ]  Task:attempt_local546651347_0001_m_000001_0 is done. And is in the process of committing 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1718 ] - [ INFO ]  map 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:1718 ] - [ INFO ]  Task 'attempt_local546651347_0001_m_000001_0' done. 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:1718 ] - [ INFO ]  Finishing task: attempt_local546651347_0001_m_000001_0 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:1718 ] - [ INFO ]  map task executor complete. 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:1718 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:1718 ] - [ INFO ]  Starting task: attempt_local546651347_0001_r_000000_0 
2019-04-26 23:19:32 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:1734 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:1781 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2d9e9038 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:1796 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1165477e 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:1812 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:1812 ] - [ INFO ]  attempt_local546651347_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:1843 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local546651347_0001_m_000001_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:1843 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local546651347_0001_m_000001_0 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:1890 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:1890 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local546651347_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:1890 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local546651347_0001_m_000000_0 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:1890 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:1890 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:1890 ] - [ INFO ]  2 / 2 copied. 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:1890 ] - [ INFO ]  finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:1906 ] - [ INFO ]  Merging 2 sorted segments 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:1906 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:1906 ] - [ INFO ]  Merged 2 segments, 4 bytes to disk to satisfy reduce memory limit 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:1921 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 23:19:32 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:1921 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:1921 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:1921 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:1921 ] - [ INFO ]  2 / 2 copied. 
2019-04-26 23:19:32 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:1921 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:1921 ] - [ INFO ]  Task:attempt_local546651347_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:1921 ] - [ INFO ]  reduce > reduce 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:1937 ] - [ INFO ]  Task 'attempt_local546651347_0001_r_000000_0' done. 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:1937 ] - [ INFO ]  Finishing task: attempt_local546651347_0001_r_000000_0 
2019-04-26 23:19:32 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:1937 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 23:19:33 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:1985 ] - [ INFO ]  Job job_local546651347_0001 running in uber mode : false 
2019-04-26 23:19:33 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:1987 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 23:19:33 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:1988 ] - [ INFO ]  Job job_local546651347_0001 completed successfully 
2019-04-26 23:19:33 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:2008 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=101658
		FILE: Number of bytes written=757093
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=742
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=9
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=978321408
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 23:20:59 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 23:20:59 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:0 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 23:20:59 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:250 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 23:20:59 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:265 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 23:20:59 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:281 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 23:20:59 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:312 ] - [ INFO ]  number of splits:2 
2019-04-26 23:20:59 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:500 ] - [ INFO ]  Submitting tokens for job: job_local1270013159_0001 
2019-04-26 23:20:59 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:687 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 23:20:59 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:687 ] - [ INFO ]  Running job: job_local1270013159_0001 
2019-04-26 23:20:59 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:687 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 23:20:59 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:687 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 23:20:59 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:750 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 23:20:59 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:750 ] - [ INFO ]  Starting task: attempt_local1270013159_0001_m_000000_0 
2019-04-26 23:20:59 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:781 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:875 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4694dc7b 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:875 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:953 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:953 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:953 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:953 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:953 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:968 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:1078 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 23:21:00 [org.apache.hadoop.io.compress.zlib.ZlibFactory.<clinit>(ZlibFactory.java:51)] - [ LocalJobRunner Map Task Executor #0:1110 ] - [ WARN ]  Failed to load/initialize native-zlib library 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1110 ] - [ INFO ]   
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:1110 ] - [ INFO ]  Starting flush of map output 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:1141 ] - [ INFO ]  Task:attempt_local1270013159_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1157 ] - [ INFO ]   
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Task.commit(Task.java:1162)] - [ LocalJobRunner Map Task Executor #0:1157 ] - [ INFO ]  Task attempt_local1270013159_0001_m_000000_0 is allowed to commit now 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] - [ LocalJobRunner Map Task Executor #0:1157 ] - [ INFO ]  Saved output of task 'attempt_local1270013159_0001_m_000000_0' to file:/E:/test/mobile_log/20180620/833/02/_temporary/0/task_local1270013159_0001_m_000000 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1157 ] - [ INFO ]  map 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:1157 ] - [ INFO ]  Task 'attempt_local1270013159_0001_m_000000_0' done. 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:1157 ] - [ INFO ]  Finishing task: attempt_local1270013159_0001_m_000000_0 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:1157 ] - [ INFO ]  Starting task: attempt_local1270013159_0001_m_000001_0 
2019-04-26 23:21:00 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:1172 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:1235 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@aba54d2 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:1250 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=3g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+837 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:1297 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:1297 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:1297 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:1297 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:1297 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:1297 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:1360 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1360 ] - [ INFO ]   
2019-04-26 23:21:00 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:1360 ] - [ INFO ]  Starting flush of map output 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  Task:attempt_local1270013159_0001_m_000001_0 is done. And is in the process of committing 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  map 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  Task 'attempt_local1270013159_0001_m_000001_0' done. 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:1375 ] - [ INFO ]  Finishing task: attempt_local1270013159_0001_m_000001_0 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:1375 ] - [ INFO ]  map task executor complete. 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:1391 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:1391 ] - [ INFO ]  Starting task: attempt_local1270013159_0001_r_000000_0 
2019-04-26 23:21:00 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:1391 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:1453 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@577a2815 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:1453 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2a92d059 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:1469 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:1485 ] - [ INFO ]  attempt_local1270013159_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:1500 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1270013159_0001_m_000001_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:1516 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local1270013159_0001_m_000001_0 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:1531 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:1547 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local1270013159_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:1547 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local1270013159_0001_m_000000_0 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:1547 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:1547 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:1547 ] - [ INFO ]  2 / 2 copied. 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:1547 ] - [ INFO ]  finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:1563 ] - [ INFO ]  Merging 2 sorted segments 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:1563 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:1563 ] - [ INFO ]  Merged 2 segments, 4 bytes to disk to satisfy reduce memory limit 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:1563 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:1563 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:1563 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:1563 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:1563 ] - [ INFO ]  2 / 2 copied. 
2019-04-26 23:21:00 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:1563 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:1578 ] - [ INFO ]  Task:attempt_local1270013159_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:1578 ] - [ INFO ]  reduce > reduce 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:1578 ] - [ INFO ]  Task 'attempt_local1270013159_0001_r_000000_0' done. 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:1578 ] - [ INFO ]  Finishing task: attempt_local1270013159_0001_r_000000_0 
2019-04-26 23:21:00 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:1578 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:1688 ] - [ INFO ]  Job job_local1270013159_0001 running in uber mode : false 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:1688 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:1688 ] - [ INFO ]  Job job_local1270013159_0001 completed successfully 
2019-04-26 23:21:00 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:1719 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=101658
		FILE: Number of bytes written=761251
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=742
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=10
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=978321408
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
2019-04-26 23:21:34 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ main:0 ] - [ INFO ]  session.id is deprecated. Instead, use dfs.metrics.session-id 
2019-04-26 23:21:34 [org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)] - [ main:0 ] - [ INFO ]  Initializing JVM Metrics with processName=JobTracker, sessionId= 
2019-04-26 23:21:34 [org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:261)] - [ main:234 ] - [ WARN ]  No job jar file set.  User classes may not be found. See Job or Job#setJar(String). 
2019-04-26 23:21:34 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:250 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 23:21:34 [org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:281)] - [ main:265 ] - [ INFO ]  Total input paths to process : 1 
2019-04-26 23:21:34 [org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:494)] - [ main:281 ] - [ INFO ]  number of splits:2 
2019-04-26 23:21:34 [org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:583)] - [ main:422 ] - [ INFO ]  Submitting tokens for job: job_local82022180_0001 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.Job.submit(Job.java:1300)] - [ main:625 ] - [ INFO ]  The url to track the job: http://localhost:8080/ 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1345)] - [ main:625 ] - [ INFO ]  Running job: job_local82022180_0001 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)] - [ Thread-3:640 ] - [ INFO ]  OutputCommitter set in config null 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)] - [ Thread-3:640 ] - [ INFO ]  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:687 ] - [ INFO ]  Waiting for map tasks 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:687 ] - [ INFO ]  Starting task: attempt_local82022180_0001_m_000000_0 
2019-04-26 23:21:35 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:718 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:796 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@499375c2 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:812 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=4g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+5724 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:893 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:893 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:893 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:893 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:893 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:893 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:1002 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 23:21:35 [org.apache.hadoop.io.compress.zlib.ZlibFactory.<clinit>(ZlibFactory.java:51)] - [ LocalJobRunner Map Task Executor #0:1033 ] - [ WARN ]  Failed to load/initialize native-zlib library 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1033 ] - [ INFO ]   
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:1033 ] - [ INFO ]  Starting flush of map output 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:1080 ] - [ INFO ]  Task:attempt_local82022180_0001_m_000000_0 is done. And is in the process of committing 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1080 ] - [ INFO ]   
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Task.commit(Task.java:1162)] - [ LocalJobRunner Map Task Executor #0:1096 ] - [ INFO ]  Task attempt_local82022180_0001_m_000000_0 is allowed to commit now 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:439)] - [ LocalJobRunner Map Task Executor #0:1096 ] - [ INFO ]  Saved output of task 'attempt_local82022180_0001_m_000000_0' to file:/E:/test/mobile_log/20180620/833/02/_temporary/0/task_local82022180_0001_m_000000 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1096 ] - [ INFO ]  map 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:1096 ] - [ INFO ]  Task 'attempt_local82022180_0001_m_000000_0' done. 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:1096 ] - [ INFO ]  Finishing task: attempt_local82022180_0001_m_000000_0 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)] - [ LocalJobRunner Map Task Executor #0:1096 ] - [ INFO ]  Starting task: attempt_local82022180_0001_m_000001_0 
2019-04-26 23:21:35 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ LocalJobRunner Map Task Executor #0:1096 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ LocalJobRunner Map Task Executor #0:1174 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@ff15d64 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:753)] - [ LocalJobRunner Map Task Executor #0:1174 ] - [ INFO ]  Processing split: file:/E:/test/log/dpiqixin/prov_id=833/day_id=20180620/net_type=3g/MBLDPI4G.2018062002_client2307.1529433045862.lzo_deflate.txt:0+837 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1202)] - [ LocalJobRunner Map Task Executor #0:1236 ] - [ INFO ]  (EQUATOR) 0 kvi 26214396(104857584) 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995)] - [ LocalJobRunner Map Task Executor #0:1236 ] - [ INFO ]  mapreduce.task.io.sort.mb: 100 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:996)] - [ LocalJobRunner Map Task Executor #0:1236 ] - [ INFO ]  soft limit at 83886080 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:997)] - [ LocalJobRunner Map Task Executor #0:1236 ] - [ INFO ]  bufstart = 0; bufvoid = 104857600 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)] - [ LocalJobRunner Map Task Executor #0:1236 ] - [ INFO ]  kvstart = 26214396; length = 6553600 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)] - [ LocalJobRunner Map Task Executor #0:1236 ] - [ INFO ]  Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:156)] - [ LocalJobRunner Map Task Executor #0:1299 ] - [ INFO ]  Found UTF-8 BOM and skipped it 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1299 ] - [ INFO ]   
2019-04-26 23:21:35 [org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1457)] - [ LocalJobRunner Map Task Executor #0:1299 ] - [ INFO ]  Starting flush of map output 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ LocalJobRunner Map Task Executor #0:1314 ] - [ INFO ]  Task:attempt_local82022180_0001_m_000001_0 is done. And is in the process of committing 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ LocalJobRunner Map Task Executor #0:1314 ] - [ INFO ]  map 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ LocalJobRunner Map Task Executor #0:1314 ] - [ INFO ]  Task 'attempt_local82022180_0001_m_000001_0' done. 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)] - [ LocalJobRunner Map Task Executor #0:1314 ] - [ INFO ]  Finishing task: attempt_local82022180_0001_m_000001_0 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:1314 ] - [ INFO ]  map task executor complete. 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)] - [ Thread-3:1314 ] - [ INFO ]  Waiting for reduce tasks 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)] - [ pool-3-thread-1:1314 ] - [ INFO ]  Starting task: attempt_local82022180_0001_r_000000_0 
2019-04-26 23:21:35 [org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.isAvailable(ProcfsBasedProcessTree.java:181)] - [ pool-3-thread-1:1330 ] - [ INFO ]  ProcfsBasedProcessTree currently is supported only on Linux. 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Task.initialize(Task.java:587)] - [ pool-3-thread-1:1377 ] - [ INFO ]   Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@54e3a4a8 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)] - [ pool-3-thread-1:1392 ] - [ INFO ]  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6a4e18a8 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:196)] - [ pool-3-thread-1:1408 ] - [ INFO ]  MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)] - [ EventFetcher for fetching Map Completion Events:1408 ] - [ INFO ]  attempt_local82022180_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:1439 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local82022180_0001_m_000000_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:1455 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local82022180_0001_m_000000_0 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:1486 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:141)] - [ localfetcher#1:1486 ] - [ INFO ]  localfetcher#1 about to shuffle output of map attempt_local82022180_0001_m_000001_0 decomp: 2 len: 6 to MEMORY 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)] - [ localfetcher#1:1486 ] - [ INFO ]  Read 2 bytes from map-output for attempt_local82022180_0001_m_000001_0 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:314)] - [ localfetcher#1:1486 ] - [ INFO ]  closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)] - [ EventFetcher for fetching Map Completion Events:1486 ] - [ INFO ]  EventFetcher is interrupted.. Returning 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:1486 ] - [ INFO ]  2 / 2 copied. 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:674)] - [ pool-3-thread-1:1486 ] - [ INFO ]  finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:1502 ] - [ INFO ]  Merging 2 sorted segments 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:1502 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:751)] - [ pool-3-thread-1:1517 ] - [ INFO ]  Merged 2 segments, 4 bytes to disk to satisfy reduce memory limit 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:781)] - [ pool-3-thread-1:1517 ] - [ INFO ]  Merging 1 files, 6 bytes from disk 
2019-04-26 23:21:35 [org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:796)] - [ pool-3-thread-1:1517 ] - [ INFO ]  Merging 0 segments, 0 bytes from memory into reduce 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:597)] - [ pool-3-thread-1:1517 ] - [ INFO ]  Merging 1 sorted segments 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:696)] - [ pool-3-thread-1:1517 ] - [ INFO ]  Down to the last merge-pass, with 0 segments left of total size: 0 bytes 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:1517 ] - [ INFO ]  2 / 2 copied. 
2019-04-26 23:21:35 [org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1049)] - [ pool-3-thread-1:1517 ] - [ INFO ]  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Task.done(Task.java:1001)] - [ pool-3-thread-1:1533 ] - [ INFO ]  Task:attempt_local82022180_0001_r_000000_0 is done. And is in the process of committing 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)] - [ pool-3-thread-1:1533 ] - [ INFO ]  reduce > reduce 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.Task.sendDone(Task.java:1121)] - [ pool-3-thread-1:1533 ] - [ INFO ]  Task 'attempt_local82022180_0001_r_000000_0' done. 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)] - [ pool-3-thread-1:1533 ] - [ INFO ]  Finishing task: attempt_local82022180_0001_r_000000_0 
2019-04-26 23:21:35 [org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)] - [ Thread-3:1533 ] - [ INFO ]  reduce task executor complete. 
2019-04-26 23:21:36 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1366)] - [ main:1642 ] - [ INFO ]  Job job_local82022180_0001 running in uber mode : false 
2019-04-26 23:21:36 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1373)] - [ main:1642 ] - [ INFO ]   map 100% reduce 100% 
2019-04-26 23:21:36 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1384)] - [ main:1642 ] - [ INFO ]  Job job_local82022180_0001 completed successfully 
2019-04-26 23:21:36 [org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1391)] - [ main:1658 ] - [ INFO ]  Counters: 33
	File System Counters
		FILE: Number of bytes read=101658
		FILE: Number of bytes written=753055
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=12
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=742
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=10
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=978321408
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0 
